{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aca64bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-19 00:58:56.908139: W external/org_tensorflow/tensorflow/tsl/platform/default/dso_loader.cc:66] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64::/usr/local/cuda-11.2/lib64:/usr/local/cuda-11.2/extras/CUPTI/lib64\n",
      "2023-03-19 00:58:56.909208: W external/org_tensorflow/tensorflow/tsl/platform/default/dso_loader.cc:66] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64::/usr/local/cuda-11.2/lib64:/usr/local/cuda-11.2/extras/CUPTI/lib64\n",
      "/root/anaconda3/envs/mpnn/lib/python3.9/site-packages/haiku/_src/data_structures.py:37: FutureWarning: jax.tree_structure is deprecated, and will be removed in a future release. Use jax.tree_util.tree_structure instead.\n",
      "  PyTreeDef = type(jax.tree_structure(None))\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import enum\n",
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3648e1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "from BH.data_loader import *\n",
    "from BH.generate_data import *\n",
    "from Model_e import Model_e,Direction,Reduction\n",
    "# from Load_Data import batch\n",
    "from Train import train,print_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8129e3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading input data...\n",
      "Generating data from the directory /Data/Ptab/n=5\n"
     ]
    }
   ],
   "source": [
    "#@title Load data\n",
    "\n",
    "#@markdown Training this model is pretty slow - an hour or so on the free tier colab, but subject to inactivity timeouts and pre-emptions.\n",
    "\n",
    "#@markdown In order to make it possible to recreate the results from the paper reliably and quickly, we provide several helpers to either speed things up, or reduce the memory footprint:\n",
    "#@markdown * Pretrained weights - greatly speeds things up by loading the trained model parameters rather than learning from the data\n",
    "#@markdown * If you are running on a high memory machine (ie *not* on the free colab instance!) the input graph data can be loaded from a pickle (which is faster to load) and kept in memory (faster to re-use, but uses ~12Gb of memory). This makes no difference to training speed (it's only relevant for `generate_graph_data()` and `get_saliency_vectors()`).\n",
    "DIR_PATH = \"/Data/Ptab/n=5\"\n",
    "\n",
    "\n",
    "use_pretrained_weights = True  #@param{type:\"boolean\"}\n",
    "hold_graphs_in_memory = False  #@param{type:\"boolean\"}\n",
    "\n",
    "gb = 1024**3\n",
    "total_memory = psutil.virtual_memory().total / gb\n",
    "# Less than 20Gb of RAM means we need to do some things slower, but with lower memory impact - in\n",
    "# particular, we want to allow things to run on the free colab tier.\n",
    "if total_memory < 20 and hold_graphs_in_memory:\n",
    "    raise RuntimeError(f\"It is unlikely your machine (with {total_memory}Gb) will have enough memory to complete the colab's execution!\")\n",
    "\n",
    "print(\"Loading input data...\")\n",
    "\n",
    "full_dataset, train_dataset, test_dataset = load_input_data(DIR_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d19c0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = 0.001\n",
    "batch_size = 128\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "\n",
    "model = Model_e(\n",
    "    num_layers=3,\n",
    "    num_features=64,\n",
    "    num_classes=num_classes,\n",
    "    direction=Direction.BOTH,\n",
    "    reduction=Reduction.SUM,\n",
    "    apply_relu_activation=True,\n",
    "    use_mask=False,\n",
    "    share=False,\n",
    "    message_relu=True,\n",
    "    with_bias=True)\n",
    "\n",
    "loss_val_gr = jax.value_and_grad(model.loss)\n",
    "opt_init, opt_update = optax.adam(step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6cf2ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset.features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94a0bcd2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:jax._src.lib.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
      "/root/anaconda3/envs/mpnn/lib/python3.9/site-packages/haiku/_src/base.py:406: UserWarning: Explicitly requested dtype float64 requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return init(shape, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (5, 256)\n",
      "msg_vect (15, 64)\n",
      "msg_out (15, 64)\n",
      "jnp (5, 4, 64)\n",
      "jnp (5, 64)\n",
      "msgs_1 (5, 64)\n",
      "msgs (5, 128)\n",
      "h2 (5, 64)\n",
      "shape (5, 256)\n",
      "msg_vect (15, 64)\n",
      "msg_out (15, 64)\n",
      "jnp (5, 4, 64)\n",
      "jnp (5, 64)\n",
      "msgs_1 (5, 64)\n",
      "msgs (5, 128)\n",
      "h2 (5, 64)\n",
      "shape (5, 256)\n",
      "msg_vect (15, 64)\n",
      "msg_out (15, 64)\n",
      "jnp (5, 4, 64)\n",
      "jnp (5, 64)\n",
      "msgs_1 (5, 64)\n",
      "msgs (5, 128)\n",
      "h2 (5, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/mpnn/lib/python3.9/site-packages/haiku/_src/data_structures.py:143: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.\n",
      "  leaves, treedef = jax.tree_flatten(tree)\n",
      "/root/anaconda3/envs/mpnn/lib/python3.9/site-packages/haiku/_src/data_structures.py:144: FutureWarning: jax.tree_unflatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_unflatten instead.\n",
      "  return jax.tree_unflatten(treedef, leaves)\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "trained_params = model.net.init(\n",
    "    jax.random.PRNGKey(42),\n",
    "    features=train_dataset.features[0],\n",
    "    rows=train_dataset.rows[0],\n",
    "    cols=train_dataset.columns[0],\n",
    "    batch_size=1,\n",
    "    edge_types=train_dataset.edge_types[0])\n",
    "trained_opt_state = opt_init(trained_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d291095b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_rows[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1863138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_edges[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e0664cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2, ..., 637, 638, 639], dtype=int16)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2159d63d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (640, 256)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Indexer must have integer or boolean type, got indexer with type float32 at position 0, indexer value Traced<ShapedArray(float32[5,1])>with<DynamicJaxprTrace(level=0/2)>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 29\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(features_train), batch_size):\n\u001b[1;32m     21\u001b[0m     b_features, b_rows, b_cols, b_ys, b_edges \u001b[38;5;241m=\u001b[39m batch(\n\u001b[1;32m     22\u001b[0m         features_train[i:i \u001b[38;5;241m+\u001b[39m batch_size],\n\u001b[1;32m     23\u001b[0m         rows_train[i:i \u001b[38;5;241m+\u001b[39m batch_size],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m         edge_types_train[i:i \u001b[38;5;241m+\u001b[39m batch_size],\n\u001b[1;32m     27\u001b[0m     )\n\u001b[0;32m---> 29\u001b[0m     trained_params, trained_opt_state, curr_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_val_gr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopt_update\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrained_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrained_opt_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mb_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mb_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mb_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mb_ys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mb_edges\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     accs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39maccuracy(\n\u001b[1;32m     42\u001b[0m         trained_params,\n\u001b[1;32m     43\u001b[0m         b_features,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m         b_edges,\n\u001b[1;32m     48\u001b[0m     )\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28mprint\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow(),\n\u001b[1;32m     50\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m4d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Batch loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurr_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     51\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch accuracy \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccs\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Min/Ptab/Train.py:6\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(loss_val_gr, opt_update, params, opt_state, features, rows, cols, ys, masks)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(loss_val_gr,opt_update,params, opt_state, features, rows, cols, ys, masks):\n\u001b[0;32m----> 6\u001b[0m   curr_loss, gradient \u001b[38;5;241m=\u001b[39m \u001b[43mloss_val_gr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m   updates, opt_state \u001b[38;5;241m=\u001b[39m opt_update(gradient, opt_state)\n\u001b[1;32m      8\u001b[0m   new_params \u001b[38;5;241m=\u001b[39m optax\u001b[38;5;241m.\u001b[39mapply_updates(params, updates)\n",
      "    \u001b[0;31m[... skipping hidden 26 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Min/Ptab/Model_e.py:244\u001b[0m, in \u001b[0;36mModel_e.loss\u001b[0;34m(self, params, features, rows, cols, ys, masks)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mpartial(jax\u001b[38;5;241m.\u001b[39mjit, static_argnums\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m,))\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(\u001b[38;5;28mself\u001b[39m, params, features, rows, cols, ys, masks):\n\u001b[0;32m--> 244\u001b[0m   _, lgts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mjnp\u001b[38;5;241m.\u001b[39mmean(\n\u001b[1;32m    247\u001b[0m       jax\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mlog_softmax(lgts) \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    248\u001b[0m       jnp\u001b[38;5;241m.\u001b[39msqueeze(jax\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mone_hot(ys, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_classes), \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/mpnn/lib/python3.9/site-packages/haiku/_src/transform.py:127\u001b[0m, in \u001b[0;36mwithout_state.<locals>.apply_fn\u001b[0;34m(params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    121\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    122\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHaiku transform adds three arguments (params, state, rng) to apply. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf the functions you are transforming use the same names you must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpass them positionally (e.g. `f.apply(.., my_state)` and not by \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname (e.g. `f.apply(.., state=my_state)`)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 127\u001b[0m out, state \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state:\n\u001b[1;32m    129\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf your transformed function uses `hk.\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mget,set}_state` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    130\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthen use `hk.transform_with_state`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/mpnn/lib/python3.9/site-packages/haiku/_src/transform.py:400\u001b[0m, in \u001b[0;36mtransform_with_state.<locals>.apply_fn\u001b[0;34m(params, state, rng, *args, **kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m base\u001b[38;5;241m.\u001b[39mnew_context(params\u001b[38;5;241m=\u001b[39mparams, state\u001b[38;5;241m=\u001b[39mstate, rng\u001b[38;5;241m=\u001b[39mrng) \u001b[38;5;28;01mas\u001b[39;00m ctx:\n\u001b[1;32m    399\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 400\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    401\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m jax\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mUnexpectedTracerError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m jax\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mUnexpectedTracerError(unexpected_tracer_hint) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/Min/Ptab/Model_e.py:224\u001b[0m, in \u001b[0;36mModel_e._kl_net\u001b[0;34m(self, features, rows, cols, batch_size, edge_types)\u001b[0m\n\u001b[1;32m    222\u001b[0m hiddens\u001b[38;5;241m.\u001b[39mappend(jnp\u001b[38;5;241m.\u001b[39mreshape(hidden, (batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_features)))\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m gnn \u001b[38;5;129;01min\u001b[39;00m gnns:\n\u001b[0;32m--> 224\u001b[0m   hidden \u001b[38;5;241m=\u001b[39m \u001b[43mgnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\u001b[43medge_types\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m   hiddens\u001b[38;5;241m.\u001b[39mappend(jnp\u001b[38;5;241m.\u001b[39mreshape(hidden, (batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_features)))\n\u001b[1;32m    227\u001b[0m hidden \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mreshape(hidden, (batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_features))\n",
      "File \u001b[0;32m~/anaconda3/envs/mpnn/lib/python3.9/site-packages/haiku/_src/module.py:433\u001b[0m, in \u001b[0;36mwrap_method.<locals>.wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m   local_name \u001b[38;5;241m=\u001b[39m module_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    431\u001b[0m   f \u001b[38;5;241m=\u001b[39m stateful\u001b[38;5;241m.\u001b[39mnamed_call(f, name\u001b[38;5;241m=\u001b[39mlocal_name)\n\u001b[0;32m--> 433\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;66;03m# Module names are set in the constructor. If `f` is the constructor then\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;66;03m# its name will only be set **after** `f` has run. For methods other\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;66;03m# than `__init__` we need the name before running in order to wrap their\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;66;03m# execution with `named_call`.\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/mpnn/lib/python3.9/site-packages/haiku/_src/module.py:284\u001b[0m, in \u001b[0;36mrun_interceptors\u001b[0;34m(bound_method, method_name, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;124;03m\"\"\"Runs any method interceptors or the original method.\"\"\"\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m interceptor_stack:\n\u001b[0;32m--> 284\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m ctx \u001b[38;5;241m=\u001b[39m MethodContext(module\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    287\u001b[0m                     method_name\u001b[38;5;241m=\u001b[39mmethod_name,\n\u001b[1;32m    288\u001b[0m                     orig_method\u001b[38;5;241m=\u001b[39mbound_method)\n\u001b[1;32m    289\u001b[0m interceptor_stack_copy \u001b[38;5;241m=\u001b[39m interceptor_stack\u001b[38;5;241m.\u001b[39mclone()\n",
      "File \u001b[0;32m~/Min/Ptab/Model_e.py:127\u001b[0m, in \u001b[0;36mMPNN_e.__call__\u001b[0;34m(self, features, rows, cols, edge_types)\u001b[0m\n\u001b[1;32m    125\u001b[0m   msgs \u001b[38;5;241m=\u001b[39m reduction(cols, rows, edge_types,msg_1_2, msg_2_2)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdirection \u001b[38;5;241m==\u001b[39m Direction\u001b[38;5;241m.\u001b[39mBOTH:\n\u001b[0;32m--> 127\u001b[0m   msgs_1 \u001b[38;5;241m=\u001b[39m \u001b[43mreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmsg_1_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg_2_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m   msgs_2 \u001b[38;5;241m=\u001b[39m reduction(cols, rows, edge_types,msg_1_2, msg_2_2)\n\u001b[1;32m    129\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmsgs_1\u001b[39m\u001b[38;5;124m\"\u001b[39m,msgs_1\u001b[38;5;241m.\u001b[39mshape)\n",
      "    \u001b[0;31m[... skipping hidden 9 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Min/Ptab/Model_e.py:71\u001b[0m, in \u001b[0;36mMPNN_e.__init__.<locals>.jax_coo_sum\u001b[0;34m(rows, cols, edge_types, msg_in, msg_out)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;129m@jax\u001b[39m\u001b[38;5;241m.\u001b[39mjit\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjax_coo_sum\u001b[39m(rows, cols, edge_types, msg_in, msg_out):\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m#       msg_vect = msg_in[rows][edge_types] + msg_out[cols][edge_types]\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m       msg_vect \u001b[38;5;241m=\u001b[39m \u001b[43mmessage_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43medge_types\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m message_stack(msg_out,cols,edge_types)\n\u001b[1;32m     72\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m message_relu:\n\u001b[1;32m     73\u001b[0m         msg_vect \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mrelu(msg_vect)\n",
      "File \u001b[0;32m~/Min/Ptab/Model_e.py:11\u001b[0m, in \u001b[0;36mmessage_stack\u001b[0;34m(messages, rows, edge_types)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmessage_stack\u001b[39m(messages,rows,edge_types):\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#   print(\"shape\",messages.shape)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#   print(\"shape\",messages[rows[0]].shape)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#   print(edge_types[0])\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#   print(\"shape\",(messages[rows[0]])[edge_types[0]].shape)\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m jnp\u001b[38;5;241m.\u001b[39mstack([messages[rows[i]][edge_types[i]] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(rows))],axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Min/Ptab/Model_e.py:11\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmessage_stack\u001b[39m(messages,rows,edge_types):\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#   print(\"shape\",messages.shape)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#   print(\"shape\",messages[rows[0]].shape)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#   print(edge_types[0])\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#   print(\"shape\",(messages[rows[0]])[edge_types[0]].shape)\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m jnp\u001b[38;5;241m.\u001b[39mstack([\u001b[43mmessages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43medge_types\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(rows))],axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/mpnn/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py:3828\u001b[0m, in \u001b[0;36m_rewriting_take\u001b[0;34m(arr, idx, indices_are_sorted, unique_indices, mode, fill_value)\u001b[0m\n\u001b[1;32m   3825\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m lax\u001b[38;5;241m.\u001b[39mdynamic_index_in_dim(arr, idx, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3827\u001b[0m treedef, static_idx, dynamic_idx \u001b[38;5;241m=\u001b[39m _split_index_for_jit(idx, arr\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m-> 3828\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_gather\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtreedef\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatic_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdynamic_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_are_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3829\u001b[0m \u001b[43m               \u001b[49m\u001b[43munique_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mpnn/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py:3837\u001b[0m, in \u001b[0;36m_gather\u001b[0;34m(arr, treedef, static_idx, dynamic_idx, indices_are_sorted, unique_indices, mode, fill_value)\u001b[0m\n\u001b[1;32m   3834\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gather\u001b[39m(arr, treedef, static_idx, dynamic_idx, indices_are_sorted,\n\u001b[1;32m   3835\u001b[0m             unique_indices, mode, fill_value):\n\u001b[1;32m   3836\u001b[0m   idx \u001b[38;5;241m=\u001b[39m _merge_static_and_dynamic_indices(treedef, static_idx, dynamic_idx)\n\u001b[0;32m-> 3837\u001b[0m   indexer \u001b[38;5;241m=\u001b[39m \u001b[43m_index_to_gather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# shared with _scatter_update\u001b[39;00m\n\u001b[1;32m   3838\u001b[0m   y \u001b[38;5;241m=\u001b[39m arr\n\u001b[1;32m   3840\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/mpnn/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py:4125\u001b[0m, in \u001b[0;36m_index_to_gather\u001b[0;34m(x_shape, idx, normalize_indices)\u001b[0m\n\u001b[1;32m   4121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (abstract_i \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m   4122\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m (issubdtype(abstract_i\u001b[38;5;241m.\u001b[39mdtype, integer) \u001b[38;5;129;01mor\u001b[39;00m issubdtype(abstract_i\u001b[38;5;241m.\u001b[39mdtype, bool_))):\n\u001b[1;32m   4123\u001b[0m   msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndexer must have integer or boolean type, got indexer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4124\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith type \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m at position \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, indexer value \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 4125\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(abstract_i\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mname, idx_pos, i))\n\u001b[1;32m   4127\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndexing mode not yet supported. Open a feature request!\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4128\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(idx))\n",
      "\u001b[0;31mTypeError\u001b[0m: Indexer must have integer or boolean type, got indexer with type float32 at position 0, indexer value Traced<ShapedArray(float32[5,1])>with<DynamicJaxprTrace(level=0/2)>"
     ]
    }
   ],
   "source": [
    "for ep in range(1, num_epochs + 1):\n",
    "    tr_data = list(\n",
    "        zip(\n",
    "            train_dataset.features,\n",
    "            train_dataset.rows,\n",
    "            train_dataset.columns,\n",
    "            train_dataset.labels,\n",
    "            train_dataset.edge_types,\n",
    "        ))\n",
    "    random.shuffle(tr_data)\n",
    "    features_train, rows_train, cols_train, ys_train, edge_types_train = zip(\n",
    "        *tr_data)\n",
    "\n",
    "    features_train = list(features_train)\n",
    "    rows_train = list(rows_train)\n",
    "    cols_train = list(cols_train)\n",
    "    ys_train = np.array(ys_train)\n",
    "    edge_types_train = list(edge_types_train)\n",
    "\n",
    "    for i in range(0, len(features_train), batch_size):\n",
    "        b_features, b_rows, b_cols, b_ys, b_edges = batch_e(\n",
    "            features_train[i:i + batch_size],\n",
    "            rows_train[i:i + batch_size],\n",
    "            cols_train[i:i + batch_size],\n",
    "            ys_train[i:i + batch_size],\n",
    "            edge_types_train[i:i + batch_size],\n",
    "        )\n",
    "\n",
    "        trained_params, trained_opt_state, curr_loss = train(\n",
    "            loss_val_gr,\n",
    "            opt_update,\n",
    "            trained_params,\n",
    "            trained_opt_state,\n",
    "            b_features,\n",
    "            b_rows,\n",
    "            b_cols,\n",
    "            b_ys,\n",
    "            b_edges,\n",
    "        )\n",
    "\n",
    "        accs = model.accuracy(\n",
    "            trained_params,\n",
    "            b_features,\n",
    "            b_rows,\n",
    "            b_cols,\n",
    "            b_ys,\n",
    "            b_edges,\n",
    "        )\n",
    "        print(datetime.datetime.now(),\n",
    "              f\"Iteration {i:4d} | Batch loss {curr_loss:.6f}\",\n",
    "              f\"Batch accuracy {accs:.2f}\")\n",
    "\n",
    "    print(datetime.datetime.now(), f\"Epoch {ep:2d} completed!\")\n",
    "\n",
    "    # Calculate accuracy across full dataset once per epoch\n",
    "    print(datetime.datetime.now(), f\"Epoch {ep:2d}       | \", end=\"\")\n",
    "    print_accuracies(model,trained_params, test_dataset, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add9fa69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpnn",
   "language": "python",
   "name": "mpnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
